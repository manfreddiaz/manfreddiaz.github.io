<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Manfred Diaz</title> <meta name="author" content="Manfred Diaz"/> <meta name="description" content="Manfred's Personal Website "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://manfreddiaz.github.io/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">open source</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Manfred</span> Diaz </h1> <em class="desc">Ph. D candidate at <a href="http://mila.quebec/" target="_blank" rel="noopener noreferrer">Mila</a> and <a href="https://montrealrobotics.ca/" target="_blank" rel="noopener noreferrer">Montreal Robotics</a>.</em> </header> <br> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p></p> <center> <i class="fa fa-map-marker" aria-hidden="true"></i> Montreal, QC, Canada</center> </div> </div> <div class="clearfix"> <p>I am a final year PhD candidate in Machine Learning and Robotics at <a href="http://mila.quebec/" target="_blank" rel="noopener noreferrer">Mila</a> under the supervision of <a href="http://liampaull.ca" target="_blank" rel="noopener noreferrer">Liam Paull</a> with a keen interest in AI and machine learning (ML) shared roots with other scientific disciplines exploring human-built structures and interactions, such as economics, game theory, mechanism design, and social choice theory. Primarily, my research focuses on how various problems at the foundations of ML mirror those in these other disciplines and how these connections offer well-grounded frameworks for better understanding the present and shaping the future of AI. I have interned at <a href="https://x.company" target="_blank" rel="noopener noreferrer">Google X</a>, <a href="https://www.jpmorgan.com/technology/artificial-intelligence" target="_blank" rel="noopener noreferrer">J.P. Morgan AI Research</a>, <a href="https://motional.com" target="_blank" rel="noopener noreferrer">Motional Inc.</a>, and <a href="https://www.huawei.com/ca/technology-insights/industry-insights/technology/ai" target="_blank" rel="noopener noreferrer">Huawei Noah’s Ark Lab Canada</a>.</p> <p>Earlier, I graduated from Concordia University with an M.Sc. in Computer Science under <a href="http://users.encs.concordia.ca/~fevens/" target="_blank" rel="noopener noreferrer">Thomas Fevens</a>. Simultaneously, I spent a year as a visiting researcher in the <a href="https://srl.mcgill.ca/" target="_blank" rel="noopener noreferrer">Shared Reality Lab</a> at McGill University under the supervision of Jeremy Cooperstock. Before, I completed a B.Sc. in Computer Science <em>summa cum laude</em> from Universidad de las Ciencias Informaticas in Havana, Cuba.</p> </div> <div class="news"> <h5 class="font-weight-bold">News</h5> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jul 29, 2022</th> <td> I gave an invited talk on <a href="https://openreview.net/forum?id=HIc8rQv-LZq" target="_blank" rel="noopener noreferrer">Generalization Games for RL</a> at <a href="https://sites.google.com/view/berkeleymarl/home" target="_blank" rel="noopener noreferrer">Berkeley MALS</a> and <a href="">Mila RL Sofa</a>. Access the recording <a href="https://bluejeans.com/s/Em67C5ydLnq" target="_blank" rel="noopener noreferrer">here</a>. </td> </tr> <tr> <th scope="row">Jun 20, 2022</th> <td> I started as a Research Intern at J. P. Morgan AI Research in London! </td> </tr> <tr> <th scope="row">Mar 28, 2022</th> <td> Our paper <a href="https://openreview.net/forum?id=HIc8rQv-LZq" target="_blank" rel="noopener noreferrer">Generalization Games for Reinforcement Learning</a> has been accepted for presentation at ICLR workshop on <a href="https://www.gamificationmas.com/" target="_blank" rel="noopener noreferrer">Gamification and Multiagent Solutions</a>. </td> </tr> </table> </div> </div> <h5 class="font-weight-bold">Selected Publications</h5> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/3mg.svg"></div> <div id="diaz2022generalization" class="col-sm-8"> <div class="title">Generalization Games for Reinforcement Learning</div> <div class="author"> <span class="font-weight-bold">Manfred Diaz</span>, Charlie Gauthier, Glen Berseth, and <a href="http://liampaull.ca" target="_blank" rel="noopener noreferrer">Liam Paull</a> </div> <div class="periodical"> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/pdf?id=Hq_Oj9JTxq" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>In reinforcement learning (RL), the term generalization has either denoted introducing function approximation to reduce the intractability of large state and action spaces problems or designated RL agents’ ability to transfer learned experiences to one or more evaluation tasks. Recently, many subfields have emerged to understand how distributions of training tasks affect an RL agent’s performance in unseen environments. While the field is extensive and ever-growing, recent research has underlined that variability among the different approaches is not as significant. We leverage this intuition to demonstrate how current methods for generalization in RL are specializations of a general framework. We obtain the fundamental aspects of this formulation by rebuilding a Markov Decision Process (MDP) from the ground up by resurfacing the game-theoretic framework of games against nature. The two-player game that arises from considering nature as a complete player in this formulation explains how existing methods rely on learned and randomized dynamics and initial state distributions. We develop this result further by drawing inspiration from mechanism design theory to introduce the role of a principal as a third player that can modify the payoff functions of the decision-making agent and nature. The games induced by playing against the principal extend our framework to explain how learned and randomized reward functions induce generalization in RL agents. The main contribution of our work is the complete description of the Generalization Games for Reinforcement Learning, a multiagent, multiplayer, game-theoretic formal approach to study generalization methods in RL. We offer a preliminary ablation experiment of the different components of the framework. We demonstrate that a more simplified composition of the objectives that we introduce for each player leads to comparable, and in some cases superior, zero-shot generalization compared to state-of-the-art methods, all while requiring almost two orders of magnitude fewer samples.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="https://github.com/google/brax/raw/main/docs/img/braxlines/ant_diayn_skill1.gif"></div> <div id="https://doi.org/10.48550/arxiv.2110.04686" class="col-sm-8"> <div class="title">Braxlines: Fast and Interactive Toolkit for RL-driven Behavior Engineering beyond Reward Maximization</div> <div class="author"> <a href="https://sites.google.com/view/gugurus/home" target="_blank" rel="noopener noreferrer">Shixiang Shane Gu</a>, <span class="font-weight-bold">Manfred Diaz</span>, Daniel C. Freeman, Hiroki Furuta, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Seyed Kamyar Seyed Ghasemipour, Anton Raichuk, Byron David, Erik Frey, Erwin Coumans, Olivier Bachem' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '4'); ">6 more authors</span> </div> <div class="periodical"> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2110.04686" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/google/brax/tree/main/brax/experimental/braxlines" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>The goal of continuous control is to synthesize desired behaviors. In reinforcement learning (RL)-driven approaches, this is often accomplished through careful task reward engineering for efficient exploration and running an off-the-shelf RL algorithm. While reward maximization is at the core of RL, reward engineering is not the only – sometimes nor the easiest – way for specifying complex behaviors. In this paper, we introduce \braxlines, a toolkit for fast and interactive RL-driven behavior generation beyond simple reward maximization that includes Composer, a programmatic API for generating continuous control environments, and set of stable and well-tested baselines for two families of algorithms – mutual information maximization (MiMax) and divergence minimization (DMin) – supporting unsupervised skill learning and distribution sketching as other modes of behavior specification. In addition, we discuss how to standardize metrics for evaluating these algorithms, which can no longer rely on simple reward maximization. Our implementations build on a hardware-accelerated Brax simulator in Jax with minimal modifications, enabling behavior synthesis within minutes of training. We hope Braxlines can serve as an interactive toolkit for rapid creation and testing of environments and behaviors, empowering explosions of future benchmark designs and new modes of RL-driven behavior generation and their algorithmic research.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="https://github.com/montrealrobotics/active-domainrand/raw/master/adr.gif"></div> <div id="pmlr-v100-mehta20a" class="col-sm-8"> <div class="title">Active Domain Randomization</div> <div class="author"> <a href="https://bhairavmehta95.github.io/" target="_blank" rel="noopener noreferrer">Bhairav Mehta</a>, <span class="font-weight-bold">Manfred Diaz</span>, Florian Golemo, Christopher J. Pal, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Liam Paull' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '4'); ">1 more author</span> </div> <div class="periodical"> 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://proceedings.mlr.press/v100/mehta20a/mehta20a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/montrealrobotics/active-domainrand" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Domain randomization is a popular technique for improving domain transfer, often used in a zero-shot setting when the target domain is unknown or cannot easily be used for training. In this work, we empirically examine the effects of domain randomization on agent generalization. Our experiments show that domain randomization may lead to suboptimal, high-variance policies, which we attribute to the uniform sampling of environment parameters. We propose Active Domain Randomization, a novel algorithm that learns a parameter sampling strategy. Our method looks for the most informative environment variations within the given randomization ranges by leveraging the discrepancies of policy rollouts in randomized and reference environment instances. We find that training more frequently on these instances leads to better overall agent generalization. Our experiments across various physics-based simulated and real-robot tasks show that this enhancement leads to more robust, consistent policies.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/walking_straight.gif"></div> <div id="Diaz_2017_ICCV" class="col-sm-8"> <div class="title">To Veer or Not to Veer: Learning From Experts How to Stay Within the Crosswalk</div> <div class="author"> <span class="font-weight-bold">Manfred Diaz</span>, Roger Girgis, <a href="http://users.encs.concordia.ca/~fevens/" target="_blank" rel="noopener noreferrer">Thomas Fevens</a>, and Jeremy Cooperstock</div> <div class="periodical"> Oct 2017 </div> <div class="links"> <a href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w22/Diaz_To_Veer_or_ICCV_2017_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="" class="btn btn-sm z-depth-0" role="button">Code</a> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%74%61%6B%65%69%74%61%6C%6C%73%6F%75%72%63%65@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=z_vFbp8AAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/manfreddiaz" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/manfreddiaz" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/linuxpotter" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> Feel free to reach out through Email or Twitter. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Manfred Diaz. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. Last updated: October 01, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>